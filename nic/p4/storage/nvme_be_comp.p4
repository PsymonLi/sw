/*****************************************************************************
 * nvme_be_comp.p4: This models the the NVME backend functionality in the P4+ 
 *                  pipeline of Capri for processing NVME completions and 
 *                  submitting them back to ROCE2NVME
 *****************************************************************************/

/*****************************************************************************
 * High level notes regarding P4 tables/action and translation to Capri asm:
 * Table:  1. Fields in "reads" form the k-vector in asm
 *            Note: Masked fields are not used in lookup in this stage       
 *         2. Data read from lookup (memory access in our case) becomes args 
 *            to action handler and the d-vector in asm
 * Action: 1. Can use the arguments as d-vector and do table writes to those
 *         2. Can use fields defined in reads as k-vector and read those
 *         3. Can write to any area in PHV (the metadata)
 *         4. Can do a posted write to any memory location as long as address
 *            is known
 * Misc:   For locked table accesses:
 *         1. All pop operations to be aligned in stages 1/2
 *         2. All push operations to be aligned to stage 8
 *****************************************************************************/

#include "common/capri.h"
#include "common/target.h"
#include "common/dummy.p4"


/*****************************************************************************
 *  Stage: Check SSD CQ context. If busy bit set, yield control. Else 
 *         set the busy bit, save SQ context to PHV and load CQ entry.
 *****************************************************************************/

action qcheck(idx, state, c_ndx, p_ndx, p_ndx_db, c_ndx_db, 
              base_addr, num_entries, paired_q_idx, rsvd) {

  // Initialize Capri Intrinsic PHV to get the fields generated by NCC
  CAPRI_INTRINSIC_INIT(intrinsic)

  // Initialize NVME backend fields to get the field generated by NCC
  modify_field(nvme_be.cmd_index, 0);
  modify_field(nvme_be.got_cmd, 0);
  modify_field(nvme_be.pad, 0);

  // Save the SQ context into PHV
  modify_field(scq_ctx.idx, idx);
  modify_field(scq_ctx.state, state);
  modify_field(scq_ctx.c_ndx, c_ndx);
  modify_field(scq_ctx.p_ndx, p_ndx);
  modify_field(scq_ctx.p_ndx_db, p_ndx_db);
  modify_field(scq_ctx.c_ndx_db, c_ndx_db);
  modify_field(scq_ctx.num_entries, num_entries);
  modify_field(scq_ctx.base_addr, base_addr);
  modify_field(scq_ctx.paired_q_idx, paired_q_idx);
  modify_field(scq_ctx.rsvd, rsvd);

  // If busy state was set or queue is empty => yield control
  if (QUEUE_CANT_POP(scq_ctx)) {
    exit();

  // Process the CQ context by locking it and loading the address for next stage
  } else {
    QUEUE_LOCK_AND_LOAD(scq_ctx, intrinsic, SSD_CQ_ENTRY_SIZE,
                        SSD_CQ_ENTRY_SIZE, ssd_cq_entry_pop)
  }
}

table ssd_cq_ctx {
  reads {
    // Non masked fields (used in lookup)
    intrinsic.table_addr_raw			: exact;
  }
  actions {
    qcheck;
  }
}

control process_ssd_cq_ctx_check {
  apply(ssd_cq_ctx);
}


/*****************************************************************************
 *  Stage: Save the NVME status entry in CQ to PHV. Increment consumer index in 
 *         CQ context to pop the entry. Load the address of the command index
 *         that was allocated in the SSD saved command list for the next stage.
 *****************************************************************************/

action qpop(nvme_status) {

  // Carry forward state information in the PHV
  modify_field(nvme_be_resp.nvme_status, nvme_status);
  
  // Derive the save command index from the NVME status
  modify_field(nvme_be.cmd_index, (0xFF &
               (nvme_be_resp.nvme_status >> NVME_STA_CID_OFFSET_END)));

  // Pop the entry from the SSD CQ
  QUEUE_POP(scq_ctx, SSD_CQ_CTX_TABLE_BASE)

  // Load the address of the saved NVME backend command for the next stage.
  // TODO: Verify if idx of SSD CQ is the same as idx of NVME backend SQ
  //       Else this logic won't work
  CAPRI_LOAD_TABLE_IDX(intrinsic, 
                       SSD_CMDS_TABLE_BASE +
                       (scq_ctx.idx * SSD_CMDS_ENTRY_SIZE) +
                       SSD_CMDS_HEADER_SIZE,
                       nvme_be.cmd_index, NVME_BE_SQ_ENTRY_SIZE,
                       R2N_NVME_HDR_SIZE, ssd_saved_cmd_handle)
}

table ssd_cq_entry {
  reads {
    // Non masked fields (used in lookup)
    intrinsic.table_addr_raw			: exact;
  }
  actions {
    qpop;
  }
}

control process_ssd_cq_entry_pop {
  apply(ssd_cq_entry);
}


/*****************************************************************************
 *  Stage: Read and process the NVME backend command that was saved before 
 *         sending to SSD. Form NVME backend status based on this. Load the 
 *         address of the SSD info table to update the running counters in the
 *         next stage.
 *****************************************************************************/

action handle(src_queue_id, ssd_handle, io_priority, is_read, cmd_handle) {

  // Carry forward state information in the PHV
  COPY_NVME_CMD1(nvme_be_cmd)

  // Set the fields in the response. TODO: Fill time_us
  modify_field(nvme_be_resp.time_us, 0);
  modify_field(nvme_be_resp.be_status, 0);
  modify_field(nvme_be_resp.rsvd, 0);
  modify_field(nvme_be_resp.cmd_handle, 
               nvme_be_cmd.cmd_handle);
  if (nvme_be_cmd.src_queue_id == 0) {
    modify_field(nvme_be_resp.is_q0, 1);
  } else {
    modify_field(nvme_be_resp.is_q0, 0);
  }

  // Load the address of the SSD info for the next stage
  // TODO: Verify if idx of SSD CQ is the same as idx of NVME backend SQ
  //       Else this logic won't work
  CAPRI_LOAD_TABLE_IDX(intrinsic, SSD_INFO_TABLE_BASE, 
                       scq_ctx.idx, SSD_INFO_ENTRY_SIZE, 
                       SSD_INFO_ENTRY_SIZE, ssd_info_update)
}

table ssd_saved_cmds1 {
  reads {
    // Non masked fields (used in lookup)
    intrinsic.table_addr_raw			: exact;
  }
  actions {
    handle;
  }
}

control process_ssd_saved_cmd_handle {
  apply(ssd_saved_cmds1);
}


/*****************************************************************************
 *  Stage: Update the SSD info table with the running counters based on 
 *         I/O command priority. Load the address of the bitmap of the 
 *         saved commands to the SSD for next stage to release.
 *****************************************************************************/

action update_weights(lo_weight, med_weight, hi_weight, lo_running, 
                      med_running, hi_running, num_running, max_cmds) {

  // Save the SSD information into PHV
  COPY_SSD_INFO(ssd_info)

  // Pop the queue entry based on priority queue from where it was dequeued
  if (nvme_be_cmd.io_priority == NVME_BE_PRIORITY_HI) {
    modify_field(ssd_info.hi_running,
                 ssd_info.hi_running - 1);
    modify_field(ssd_info.num_running,
                 ssd_info.num_running - 1);
  }
  if (nvme_be_cmd.io_priority == NVME_BE_PRIORITY_MED) {
    modify_field(ssd_info.med_running,
                 ssd_info.med_running - 1);
    modify_field(ssd_info.num_running,
                 ssd_info.num_running - 1);
  }
  if (nvme_be_cmd.io_priority == NVME_BE_PRIORITY_LO) {
    modify_field(ssd_info.lo_running,
                 ssd_info.lo_running - 1);
    modify_field(ssd_info.num_running,
                 ssd_info.num_running - 1);
  }

  // Move the next (skip) stage without loading a table. This is done to 
  // line up the stages.
  CAPRI_LOAD_NO_TABLE(intrinsic, ssd_saved_cmd_skip_stage)
}

table nvme_be_ssd_info {
  reads {
    // Non masked fields (used in lookup)
    intrinsic.table_addr_raw			: exact;
  }
  actions {
    update_weights;
  }
}

control process_ssd_info_update_weights {
  apply(nvme_be_ssd_info);
}

/*****************************************************************************
 *  Stage: Move the next (skip) stage without loading a table. This is done to 
 *         line up the stages.
 *****************************************************************************/

action skip() {
  CAPRI_LOAD_NO_TABLE(intrinsic, ssd_saved_cmd_tbl_addr_load)
}

table ssd_saved_cmd_skip_tbl {
  reads {
    // Masked fields (not used in lookup)
    scq_ctx.idx			mask 0x0	: exact;
  }
  actions {
    skip;
  }
}

control process_ssd_saved_cmd_skip_stage {
  apply(ssd_saved_cmd_skip_tbl);
}


/*****************************************************************************
 *  Stage: Load the SSD saved command table for the next stage to release it
 *****************************************************************************/

action load() {
  // Load the address of the bitmap of the saved NVME backend command for 
  // the next stage
  // TODO: Verify if idx of SSD CQ is the same as idx of NVME backend SQ
  //       Else this logic won't work
  CAPRI_LOAD_TABLE_IDX(intrinsic, SSD_CMDS_TABLE_BASE, 
                       scq_ctx.idx, SSD_CMDS_ENTRY_SIZE, 
                       SSD_CMDS_HEADER_SIZE, ssd_saved_cmd_release)
}

table ssd_saved_cmd_tbl_addr {
  reads {
    // Masked fields (not used in lookup)
    scq_ctx.idx			mask 0x0	: exact;
  }
  actions {
    load;
  }
}

control process_ssd_saved_cmd_tbl_addr_load {
  apply(ssd_saved_cmd_tbl_addr);
}


/*****************************************************************************
 *  Stage: Release the memory which contained the saved NVME command that was
 *         sent to the SSD by freeing the bit in the bitmap. Load the address
 *         of the NVME backend's CQ context for the next stage.
 *****************************************************************************/

action release(bitmap) {

  // Carry forward state information in the PHV
  modify_field(ssd_cmds.bitmap, bitmap);
  
  // Scratch metadata for the I part of the K vector
  modify_field(scratch_metadata.cmd_index, nvme_be.cmd_index);

  // Reset the cmd_index bit in the bitmap to account for it as free
  modify_field(ssd_cmds.bitmap, 
               ssd_cmds.bitmap & (~(0x1 << nvme_be.cmd_index)));

  // Load the address of the SSD's SQ for the next stage 
  // TODO: If muliple SQ's of the NVME Backend share the same CQ need to
  //       have software setup and use scq_ctx.paired_q_idx
  CAPRI_LOAD_TABLE_IDX(intrinsic, NVME_BE_CQ_CTX_TABLE_BASE, 
                       scq_ctx.idx, Q_CTX_SIZE, Q_CTX_SIZE, 
                       nvme_be_cq_entry_push)
}

table ssd_saved_cmds2 {
  reads {
    // Non masked fields (used in lookup)
    intrinsic.table_addr_raw			: exact;
  }
  actions {
    release;
  }
}

control process_ssd_saved_cmd_release {
  apply(ssd_saved_cmds2);
}



/*****************************************************************************
 *  Stage: Push NVME backend status to Roce2Nvme over the NVME backend CQ
 *****************************************************************************/

action qpush(idx, state, c_ndx, p_ndx, p_ndx_db, c_ndx_db, base_addr,
                       num_entries, paired_q_idx, rsvd) {

  // Write back the fields passed in to avoid P4 compiler warnings
  // of unused fields. No need to translate this to asm.
  modify_field(ncq_ctx.idx, idx);
  modify_field(ncq_ctx.state, state);
  modify_field(ncq_ctx.p_ndx, p_ndx);
  modify_field(ncq_ctx.c_ndx, c_ndx);
  modify_field(ncq_ctx.p_ndx_db, p_ndx_db);
  modify_field(ncq_ctx.c_ndx_db, c_ndx_db);
  modify_field(ncq_ctx.base_addr, base_addr);
  modify_field(ncq_ctx.num_entries, num_entries);
  modify_field(ncq_ctx.paired_q_idx, paired_q_idx);
  modify_field(ncq_ctx.rsvd, rsvd);

  // Check for queue full condition before pushing
  if (QUEUE_CANT_PUSH(ncq_ctx)) {

    // Exit pipeline here without error handling for now. This event of SSD SQ
    // being full should never happen as software will program the max_cmds to
    // be popped to a value less than the SSD's SQ size.
    exit();

  } else {

#if 0
    // Copy NVME status to SSD SQ memory. In ASM, DMA write 
    // of the fields from PHV (which are contiguous).
    dmawr(ncq_ctx.base_addr + 
          (ncq_ctx.p_ndx * NVME_BE_CQ_ENTRY_SIZE),
          nvme_be_resp.time_us ..
          nvme_be_resp.nvme_status);
#endif

    // Push the entry to the queue 
    QUEUE_PUSH(ncq_ctx)

    // Initialize the fields so that it will appear in the auto generated PHV
    CAPRI_PHV2MEM_DMA_INIT(dma_cmd0)
    CAPRI_PHV2MEM_DMA_INIT(dma_cmd1)

    // Exit the pipeline here after scheduling bit for the next pipeline
    //modify_field(scheduler.sched_bit, SCHED_BIT_R2N_COMP);
  }
}

table nvme_be_push_cq_ctx {
  reads {
    // Non masked fields (used in lookup)
    intrinsic.table_addr_raw			: exact;
  }
  actions {
    qpush;
  }
}

control process_nvme_be_cq_entry_push {
  apply(nvme_be_push_cq_ctx);
}


/*****************************************************************************
 *  Control flow: NVME backend completion handling (from SSD CQ)
 *****************************************************************************/

control process_nvme_be_comp {
  // Process SSD CQ context to check to see if busy bit is set
  process_ssd_cq_ctx_check();

  // Copy the SSD CQ entry and pop it
  process_ssd_cq_entry_pop();

  // Process the saved SSD command and form the NVME backend response
  process_ssd_saved_cmd_handle();

  // Update the running counters based on priority in the SSD information table
  process_ssd_info_update_weights();

  // Skip stage to line up stage 7 with command handling
  process_ssd_saved_cmd_skip_stage();

  // Load the SSD saved command table to release the bit in the next stage
  process_ssd_saved_cmd_tbl_addr_load();

  // Release the memory where the command to the SSD was saved.
  // For table locking this needs to be in stage 5 to align with the NVME 
  // backend command handling which updates this table in that stage.
  process_ssd_saved_cmd_release();

  // Push the NVME backend response command to the CQ
  process_nvme_be_cq_entry_push();

  // Exit the pipeline here
}

// Entry point 
control ingress {
    process_nvme_be_comp();
}
// Dummy parser
parser start {
  return ingress;
}
