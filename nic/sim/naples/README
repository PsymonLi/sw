
1. create a directory and copy naples-release-v1.tgz (call it install_dir)

2. cd install_dir

3. tar xvzf naples-release-v1.tgz

   once naples-release-v1.tgz is unzipped, you will find a Vagrantfile
   that is needed to VMs needed for simulating multiple data centers
   (each VM is a datacenter/kingdom)

   to create a VM needed to run NAPLES docker container. Note that
   only bare minimum packages needed to run NAPLES docker container
   are installed in this default Vagrantfile. Please feel free to add
   other packages that you may need to run your (native) apps, if any.

4. vagrant up

   This will bringup the datacenters and establish the VM connectivity between
   them. Additionally, each of the VMs will have NAPLES container running
   already with all the components of Pensando NIC. This container represents
   the NIC in the VPN gateway of that datacenter. Use 'vagrant ssh node1/node2'
   to connect to VMs

5. Posting sample policies

   Sample postman configs are placed in the home directory of each VM. Run the
   following command in both the VMs to load the sample config

   $ newman run postman_collection.json -e postman_env.json

6. If you have to spin the NAPLES container manually (in case something went wrong),
   use 'docker start/stop naples-sim' inside the VMs.
   To do a fresh re-install of the naples container, re-provision the vargant VM
   using 'vagrant up --provision'



By default, port 9007 of the docker container is exposed to the host (i.e., VM
representing the datacenter) and hence REST APIs can be invoked using curl.

Examples:

In this example, we will use the pre-created "default" tenant. The following
config is to be posted on NAT VPN gateway in kingdom 1.

Use default tenant:

curl localhost:9007/api/tenants/
[{"kind":"Tenant","meta":{"name":"default","tenant":"default","namespace":"default","creation-time":"1970-01-01T00:00:00Z","mod-time":"1970-01-01T00:00:00Z"},"spec":{},"status":{"TenantID":1}}]

To use non-default tenant, do:

curl -d'{"Kind":"Tenant","meta":{"Name":"tenant-1"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/tenants/

Create Namespaces:

curl -d'{"Kind":"Namespace","meta":{"Name":"kg1","Tenant":"default"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/namespaces/
curl -d'{"Kind":"Namespace","meta":{"Name":"kg2","Tenant":"default"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/namespaces/
curl -d'{"Kind":"Namespace","meta":{"Name":"public","Tenant":"default"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/namespaces/

Create Network object for local Kingdom (kg1) and "public" Network:

curl -d'{"Kind":"Network","meta":{"Name":"kg1","Tenant":"default","Namespace":"kg1"}, "spec":{"IPv4Subet": "10.1.1.0/24", "IPv4Gateway":"10.1.1.1", "VlanID":100}}' -X POST -H "Content-Type: application/json" localhost:9007/api/networks/
curl -d'{"Kind":"Network","meta":{"Name":"public","Tenant":"default","Namespace":"public"}, "spec":{"IPv4Subet": "20.1.1.0/24", "IPv4Gateway":"20.1.1.1", "VlanID":200}}' -X POST -H "Content-Type: application/json" localhost:9007/api/networks/

Create (remote) GW EPs:

curl -d'{"Kind":"Endpoint","Meta":{"Name":"kg1-router","Tenant":"default","Namespace":"kg1"},"spec":{"NetworkName":"kg1","Interface":"default-uplink-0"},"status":{"IPv4Address":"10.1.1.1/24","MacAddress":"00:22:22:22:22:22","NodeUUID":"GWUUID"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/endpoints/
curl -d'{"kind":"Endpoint","Meta":{"Name":"public-router","Tenant":"default","Namespace":"public"},"spec":{"NetworkName":"public","Interface":"default-uplink-1"},"status":{"IPv4Address":"20.1.1.1/24","MacAddress":"00:33:33:33:33:33","NodeUUID":"GWUUID"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/endpoints/

Create Routes:

curl -d'{"Kind":"Route","meta":{"Name":"kg1","Tenant":"default","Namespace":"kg1"}, "spec":{"ip-prefix": "10.1.1.0/24", "interface":"default-uplink-0", "gateway-ip":"10.1.1.1"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/routes/
curl -d'{"Kind":"Route","meta":{"Name":"public","Tenant":"default","Namespace":"public"}, "spec":{"ip-prefix":"20.1.1.0/24", "interface":"default-uplink-1","gateway-ip":"20.1.1.1"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/routes/
curl -d'{"Kind":"Route","meta":{"Name":"kg2","Tenant":"default","Namespace":"kg2"}, "spec":{"IPPrefix": "0.0.0.0/24", "Interface":"kg2-IPSecTunnel"}' -X POST -H "Content-Type: application/json" localhost:9007/api/routes/
curl -d'{"Kind":"Route","meta":{"Name":"kg3","Tenant":"default","Namespace":"kg3"}, "spec":{"IPPrefix": "0.0.0.0/24", "Interface":"kg3-IPSecTunnel"}' -X POST -H "Content-Type: application/json" localhost:9007/api/routes/
...
...

Create NAT pool:

curl -d'{"kind":"NatPool","meta":{"name":"pool-1","tenant":"default","namespace":"kg1"},"spec":{"ip-range":"10.100.0.0-10.100.0.255"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/natpools/

Create NAT Mappings for remote services (running in kg2):

curl -d'{"Kind":"NatBinding","meta":{"Name":"kg2-svc1","Tenant":"default","Namespace":"kg2"}, "spec":{"nat-pool":"kg1/pool-1", "ip-address":"10.0.2.15"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/natbindings/

Create NAT policy:

curl -d'{"kind":"NatPolicy","meta":{"name":"testNatPolicy","tenant":"tenant-1","namespace":"ns-1","creation-time":"1970-01-01T00:00:00Z","mod-time":"1970-01-01T00:00:00Z"},"spec":{"rules":[{"from":{"match-type":"IPRange","match":"10.0.0.0 - 10.0.1.0"},"to":{"match-type":"IPRange","match":"192.168.0.0 - 192.168.1.1"},"protocol":"","from-port":"","to-port":"","nat-pool":"preCreatedNatPool","action":"SNAT"}]},"status":{}}' -X POST -H "Content-Type: application/json" localhost:9007/api/natpolicies/


The following config applies to kg2:

Create Namespaces:

curl -d'{"Kind":"Namespace","meta":{"Name":"kg1","Tenant":"default"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/namespaces/
curl -d'{"Kind":"Namespace","meta":{"Name":"kg2","Tenant":"default"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/namespaces/
curl -d'{"Kind":"Namespace","meta":{"Name":"public","Tenant":"default"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/namespaces/


Create Network object for local Kingdom (kg2) and "public" Network:

curl -d'{"Kind":"Network","meta":{"Name":"kg2","Tenant":"default","Namespace":"kg2"}, "spec":{"IPv4Subet": "10.1.1.0/24", "IPv4Gateway":"10.1.1.1", "VlanID":100}}' -X POST -H "Content-Type: application/json" localhost:9007/api/networks/
curl -d'{"Kind":"Network","meta":{"Name":"public","Tenant":"default","Namespace":"public"}, "spec":{"IPv4Subet": "20.1.1.0/24", "IPv4Gateway":"20.1.1.2", "VlanID":200}}' -X POST -H "Content-Type: application/json" localhost:9007/api/networks/


Create (remote) GW EPs:

curl -d'{"Kind":"Endpoint","Meta":{"Name":"kg2-router","Tenant":"default","Namespace":"kg2"},"spec":{"NetworkName":"kg2","Interface":"default-uplink-0"},"status":{"IPv4Address":"10.1.1.1/24","MacAddress":"00:22:22:22:22:22","NodeUUID":"GWUUID"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/endpoints/
curl -d'{"kind":"Endpoint","Meta":{"Name":"public-router","Tenant":"default","Namespace":"public"},"spec":{"NetworkName":"public","Interface":"default-uplink-1"},"status":{"IPv4Address":"20.1.1.2/24","MacAddress":"00:33:33:33:33:33","NodeUUID":"GWUUID"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/endpoints/


Create Routes:

curl -d'{"Kind":"Route","meta":{"Name":"kg2","Tenant":"default","Namespace":"kg2"}, "spec":{"ip-prefix": "10.1.1.0/24", "interface":"default-uplink-0", "gateway-ip":"10.1.1.1"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/routes/
curl -d'{"Kind":"Route","meta":{"Name":"public","Tenant":"default","Namespace":"public"}, "spec":{"ip-prefix":"20.1.1.0/24", "interface":"default-uplink-1","gateway-ip":"20.1.1.2"}}' -X POST -H "Content-Type: application/json" localhost:9007/api/routes/
curl -d'{"Kind":"Route","meta":{"Name":"kg1","Tenant":"default","Namespace":"kg1"}, "spec":{"IPPrefix": "0.0.0.0/24", "Interface":"kg1-IPSecTunnel"}' -X POST -H "Content-Type: application/json" localhost:9007/api/routes/
curl -d'{"Kind":"Route","meta":{"Name":"kg3","Tenant":"default","Namespace":"kg3"}, "spec":{"IPPrefix": "0.0.0.0/24", "Interface":"kg3-IPSecTunnel"}' -X POST -H "Content-Type: application/json" localhost:9007/api/routes/


Create NAT pool:

curl -d'{"kind":"NatPool","meta":{"name":"kg2-natpool","tenant":"default","namespace":"kg2"},"spec":{"ip-range":"10.1.2.1-10.1.2.200"}' -X POST -H "Content-Type: application/json" localhost:9007/api/natpools/

=====

Get all NAT policies:
curl localhost:9007/api/natpolicies/ | jq .
[
  {
    "kind": "NatPolicy",
    "meta": {
      "name": "testNatPolicy",
      "tenant": "tenant-1",
      "namespace": "ns-1",
      "creation-time": "1970-01-01T00:00:00Z",
      "mod-time": "1970-01-01T00:00:00Z"
    },
    "spec": {
      "rules": [
        {
          "from": {
            "match-type": "IPRange",
            "match": "10.0.0.0 - 10.0.1.0"
          },
          "to": {
            "match-type": "IPRange",
            "match": "192.168.0.0 - 192.168.1.1"
          },
          "protocol": "",
          "from-port": "",
          "to-port": "",
          "nat-pool": "preCreatedNatPool",
          "action": "SNAT"
        }
      ]
    },
    "status": {
      "id": 1
    }
  }
]


## Sample APP

### Start server on Node2 (kingdom2)

1. Create kg2 local subnet

    [vagrant@node2 ~]$ docker network create kg2 --subnet 10.100.2.0/24

2. Start iperf3-server attached to kg2 subent

    [vagrant@node2 ~]$ docker run -it --rm --net=kg2 --name=iperf3-server networkstatic/iperf3 -s

3. Get the IP address of the iperf server 
    
    [vagrant@node2 ~]$ docker inspect --format "{{ .NetworkSettings.Networks.kg2.IPAddress }}" iperf3-server
    10.100.2.2
    
### Start client on Node1 (kingdom1) 
    
1. creaste kg1 local subnet
    
    [vagrant@node1 ~] docker network create kg1 --subnet 10.100.1.0/24

2. Start the client

    [vagrant@node1 ~] docker run  -it --rm --net=kg1 networkstatic/iperf3 -c 10.100.2.2

NOTE:

1. To check NAPLES container health, please do "docker ps" and look at the
   STATUS column

2. If STATUS is reported as "unhealthy", please do:

   "docker inspect --format "{{json .State.Health }}"  <container-id> | jq

   This should show the reason for bad health in case container is "unhealthy"

    For example:

    [root@d34a71a8b0a2 nic]# docker ps
    CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                      PORTS                    NAMES
    386c47101e22        naples:v1           "/naples/nic/tools/s…"   22 minutes ago      Up 22 minutes (unhealthy)   0.0.0.0:9007->9007/tcp   naples-v1

    [root@d34a71a8b0a2 nic]# docker inspect --format "{{json .State.Health }}"  386c47101e22 | jq
    {
      "Status": "unhealthy",
      "FailingStreak": 9,
      "Log": [
        {
          "Start": "2018-05-04T17:22:56.281835588-07:00",
          "End": "2018-05-04T17:22:56.345817966-07:00",
          "ExitCode": 1,
          "Output": "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed connect to localhost:9007; Connection refused\n"
        },
        {
          "Start": "2018-05-04T17:24:56.354681048-07:00",
          "End": "2018-05-04T17:24:56.417479099-07:00",
          "ExitCode": 1,
          "Output": "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed connect to localhost:9007; Connection refused\n"
        },
        {
          "Start": "2018-05-04T17:26:56.424463273-07:00",
          "End": "2018-05-04T17:26:57.865418911-07:00",
          "ExitCode": 1,
          "Output": "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed connect to localhost:9007; Connection refused\n"
        },
        {
          "Start": "2018-05-04T17:28:57.894402864-07:00",
          "End": "2018-05-04T17:28:58.472318062-07:00",
          "ExitCode": 1,
          "Output": "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed connect to localhost:9007; Connection refused\n"
        },
        {
          "Start": "2018-05-04T17:30:59.218133046-07:00",
          "End": "2018-05-04T17:30:59.286270659-07:00",
          "ExitCode": 1,
          "Output": "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed connect to localhost:9007; Connection refused\n"
        }
      ]
    }

3. There is no session aging in this release as the this is CAPRI s/w model, so
   in case flow keys are reused across sessions, data path state (e.g., NAT
   bindings etc.) will be reused in the data plane as well. If this is not
   intended, NAPLES container should be restarted.

Testing the branch creation.
